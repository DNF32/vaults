---
aliases:
  - agents
tags: []
title: agents
---

# agents

We call them agent because they have agency over their enviorment.
An agent reasons -> plans -> interacting with its environment.By giving this ablity to an LLM

# The Thought-Action-Observation Cycle

The agent uses a while loop to try to acomplish a task.

1.  Think about the task at hand
2.  Take action possible using a tool. The AI model has to produce the right instruction to be fed into the tool needed.
3.  Given the response from the tool evaluate if the task is solved. If not loop to 1. with the obsertation obtained.

## Notes

Some takeaways from Antropics post. How to make agentic workflows. Focus on low complexity solutions. Minimize the use of `agnecy`, for instance by combining two tool into one.

Workflows vs Agents

- workflow are predeterminted chains that an LLM follows (we can also have tools)
- Agents as the name suggests have agency on the paths they follow
- One of the main ideas is that we should use agency when there is some ambiguity in the control flow of a decision. Even better, we could constrain the control flow, but we could also use the LLM in a try: catch: manner. We can parse the cases we handle and catch only specific values, while also ensuring that our program errors out when necessary.

# SmolAgents

Lightweight a minimal. Great integration with Huggigface hub. First-class support for `code agentes`. It's always a good option even when we want to quickly prototype a solution.

smolagents supports flexible LLM integration, allowing you to use any callable model that meets certain criteria. The framework provides several predefined classes to simplify model connections:

    - Transformers Model: Implements a local transformers pipeline for seamless integration.
    - HfApiModel: Supports serverless inference calls through Hugging Face‚Äôs infrastructure, or via a growing number of third-party inference providers.
    - LiteLLMModel: essencially a wrapper from LLM clients aroind the OpenAI format.
    - OpenAIServerModel: Connects to any service that offers an OpenAI API interface
    - AzureOpenAIServerModel: Supports integration with any Azure OpenAI deployment.

# CodeAgent vs ToolcallingAgent

Code agents produce code to execute their actions, while tool calling agent use Json to call tools and pass arguments (get parsed and the executed)

# Multi agent orchertractor

The main idea is that if their are tasks that are disjoint in nature we should decouple this tasks since otherwise we would be poluting the memory of our agents, potencialy giving rise a high number of wasted tokens


# How to evaluate this agents is a big topic 
# Good phrase for tooling

Typical REST API's endpoint solve one discrete operation. For example, when a model needs to analyze calendar data and send meeting summaries via email, it can discover and compose these tools on the fly rather than requiring developenmnt of this specific combination.

# Function callling model

Models are trainned to call functions

# üß† Presentation Plan

## 1. Start by introducing raw LLMs

- Show examples of how they generate responses with a **lack of memory**.

## 2. Definition of an Agent

- An agent encapsulates:
  - Some state
  - An LLM interface
  - Possibly a vector store
  - Tool handling
- **A vector store is essentially a database optimized for similarity search ‚Äì allowing agents to quickly retrieve relevant information.** [Early explanation of a key component]
- Agents can interact with the user or other agents.
  _(The idea is to demystify the concept of tools ‚Äî we‚Äôre already using tools.)_

### Examples:

- **RAG as a tool**:
  - Different vector stores for unrelated topics.
  - Example: A customer support interaction may query a traditional database for static user info **and** use a RAG vector store to get more contextual insights.

### Types of Memory:

- **Semantic memory**: Stores facts.
- **Episodic memory**: Remembers specific examples (e.g., for few-shot learning).

## 3. Light Introduction to the ReAct Agent Model

- Describe how it works (parsing prompt outputs into reasoning and actions).
- Emphasize: **This is not a reasoning model ‚Äî it‚Äôs a clever prompt trick.**

### Examples:

- Show a **flight booking agent** with slides (no live demo).
  - **Prepare a few simple slides showing the steps: User query -> Agent action (query vector store) -> Agent response.** [Enhanced visuals]
- Orally mention other automations.
  - Use this to segue into the idea of **task complexity vs. required investment**.
- Example: **AI coding assistant agent**:
  - Start with positives.
  - Transition into real user feedback ‚Äî e.g., ‚ÄúCursor can‚Äôt fix my problem anymore.‚Äù
  - **This highlights a key aspect ‚Äì agents augment human capability, they don't replace it. Understanding their limitations is crucial.** [Reframing negative feedback]

## 4. Error Handling ‚Üí Anthropic's Post on Building Effective Agents

- Use error handling as a jumping-off point.
- Briefly walk through **each pattern** mentioned by Anthropic.
- **Create a visual summary (table or slide) of the patterns.** [Visual summary]

## 5. Project Example: Pen_Swap Scraper + Recommendation Agent

- Scrape Reddit posts from r/Pen_Swap and store them in a DB.
- Build a **recommendation agent** that self-queries the DB for good deals.
- **This demonstrates how different agents can handle distinct parts of a larger task, improving efficiency and maintainability.** [Clarifying responsibility]

## 6. Closing Notes: Accessibility and Cost

- Building agents is **easy and affordable**.
- Example: Built an agentic RAG model for only **$0.50** on the PyDantic AI documentation.
  - **This tiny dataset demonstrates that building powerful agents doesn‚Äôt always require huge resources, showing that you don‚Äôt always need to retrain LLMs or access massive datasets to create impactful applications.** [Reinforcing the example]

---

## ‚úÖ Conclusion Slide: Agents: Structured Workflows, Not Magic

- **Briefly recap what an agent is.**
- **Reiterate the structured workflow concept.**
- **Emphasize the power and accessibility of agentic LLM development.**
- **[Your main takeaway/lesson from the presentation].**

---

# Memory

## üß† Is Semantic Memory a _Tool_?

**Not exactly.**  
Semantic memory isn't a standalone _tool_ like a plugin or module ‚Äî it's a **conceptual layer of memory** that represents an AI's **built-in knowledge** of facts, language, and general world understanding.

---

### üîπ In AI Terms:

- **Semantic memory = the model's pretrained knowledge.**
- It's what the model _already knows_ before any specific conversation happens.
- It's **static** (pretrained) and **non-personalized**, unless updated or extended by tools or fine-tuning.

---

### ‚úÖ So What _Is_ a Tool?

- A **tool** is an _external system or capability_ the AI can access (e.g., web search, calculator, database).
- Tools help the model fetch or calculate information **outside** its semantic memory.

---

### üß† vs üõ†Ô∏è Quick Comparison:

| Semantic Memory            | Tool                      |
| -------------------------- | ------------------------- |
| Built-in factual knowledge | External function/system  |
| Comes from model training  | Accessed during runtime   |
| Static and general         | Dynamic and task-specific |

Just a quick note: I‚Äôm not here to hype AI agents like I‚Äôm trying to sell one‚Äîbecause I‚Äôm not. The AI space is genuinely exciting, but with that excitement comes a bit of snake oil too. A lot of Twitter demos might look impressive in short-form content, but they don‚Äôt always translate into real, reliable products.

I spli this presentation into three main section, ..., the last two mihgt seem a bit more cryptic right now ()
So let's dive in what's an AI Agent. The clue is in the name (then there appear a slide with formal defintion of agency in the oxfrod dict)

An AI agent combines an artificial intelligence system with the ability to interact with its environment and perform actions.
You can also think of agency as a spectrum‚Äî
On one end, you have basic CRUD apps that do exactly what they‚Äôre programmed to do and nothing more.
On the other, you have highly autonomous systems, like self-driving cars, that make complex decisions in real time with minimal human input.

---

UI-Tars byte dance new framework for agents, thing for controlling GUI
