---
aliases:
  - agents
tags: []
title: agents
---

# agents

We call them agent because they have agency over their enviorment.
An agent reasons -> plans -> interacting with its environment.By giving this ablity to an LLM

# The Thought-Action-Observation Cycle

The agent uses a while loop to try to acomplish a task.

1.  Think about the task at hand
2.  Take action possible using a tool. The AI model has to produce the right instruction to be fed into the tool needed.
3.  Given the response from the tool evaluate if the task is solved. If not loop to 1. with the obsertation obtained.

## Notes

Some takeaways from Antropics post. How to make agentic workflows. Focus on low complexity solutions. Minimize the use of `agnecy`, for instance by combining two tool into one.

Workflows vs Agents

- workflow are predeterminted chains that an LLM follows (we can also have tools)
- Agents as the name suggests have agency on the paths they follow
- One of the main ideas is that we should use agency when there is some ambiguity in the control flow of a decision. Even better, we could constrain the control flow, but we could also use the LLM in a try: catch: manner. We can parse the cases we handle and catch only specific values, while also ensuring that our program errors out when necessary.

# SmolAgents

Lightweight a minimal. Great integration with Huggigface hub. First-class support for `code agentes`. It's always a good option even when we want to quickly prototype a solution.

smolagents supports flexible LLM integration, allowing you to use any callable model that meets certain criteria. The framework provides several predefined classes to simplify model connections:

    - Transformers Model: Implements a local transformers pipeline for seamless integration.
    - HfApiModel: Supports serverless inference calls through Hugging Faceâ€™s infrastructure, or via a growing number of third-party inference providers.
    - LiteLLMModel: essencially a wrapper from LLM clients aroind the OpenAI format.
    - OpenAIServerModel: Connects to any service that offers an OpenAI API interface
    - AzureOpenAIServerModel: Supports integration with any Azure OpenAI deployment.

# CodeAgent vs ToolcallingAgent

Code agents produce code to execute their actions, while tool calling agent use Json to call tools and pass arguments (get parsed and the executed)

# Multi agent orchertractor

The main idea is that if their are tasks that are disjoint in nature we should decouple this tasks since otherwise we would be poluting the memory of our agents, potencialy giving rise a high number of wasted tokens


# How to evaluate this agents is a big topic 
